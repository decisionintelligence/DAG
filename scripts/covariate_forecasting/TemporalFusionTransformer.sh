python ./scripts/run_benchmark.py --config-path "rolling_forecast_config.json" --data-name-list "NP.csv" --strategy-args '{"horizon": 24, "target_channel": [-1]}' --adapter "transformer_adapter" --model-name "time_series_library.TemporalFusionTransformer" --model-hyper-params '{"batch_size": 128, "c_out": 3, "covariate_dim": 2, "d_ff": 32, "d_layers": 1, "d_model": 64, "data": "NP", "dec_in": 3, "dropout": 0.1, "e_layers": 2, "enc_in": 3, "factor": 3, "features": "MS", "horizon": 24, "label_len": 48, "lr": 0.01, "n_heads": 8, "norm": true, "num_epochs": 10, "patience": 5, "seq_len": 168}' --gpus 0 --num-workers 1 --timeout 60000 --save-path "NP/TemporalFusionTransformer"

python ./scripts/run_benchmark.py --config-path "rolling_forecast_config.json" --data-name-list "NP.csv" --strategy-args '{"horizon": 360, "target_channel": [-1]}' --adapter "transformer_adapter" --model-name "time_series_library.TemporalFusionTransformer" --model-hyper-params '{"batch_size": 128, "c_out": 3, "covariate_dim": 2, "d_ff": 32, "d_layers": 1, "d_model": 64, "data": "NP", "dec_in": 3, "dropout": 0.1, "e_layers": 2, "enc_in": 3, "factor": 3, "features": "MS", "horizon": 360, "label_len": 48, "lr": 0.01, "n_heads": 8, "norm": true, "num_epochs": 10, "patience": 5, "seq_len": 720}' --gpus 0 --num-workers 1 --timeout 60000 --save-path "NP/TemporalFusionTransformer"

python ./scripts/run_benchmark.py --config-path "rolling_forecast_config.json" --data-name-list "PJM.csv" --strategy-args '{"horizon": 24, "target_channel": [-1]}' --adapter "transformer_adapter" --model-name "time_series_library.TemporalFusionTransformer" --model-hyper-params '{"batch_size": 128, "c_out": 3, "covariate_dim": 2, "d_ff": 64, "d_layers": 1, "d_model": 128, "data": "PJM", "dec_in": 3, "dropout": 0.1, "e_layers": 1, "enc_in": 3, "factor": 3, "features": "MS", "horizon": 24, "label_len": 48, "lr": 0.001, "n_heads": 8, "norm": true, "num_epochs": 10, "patience": 5, "seq_len": 168}' --gpus 0 --num-workers 1 --timeout 60000 --save-path "PJM/TemporalFusionTransformer"

python ./scripts/run_benchmark.py --config-path "rolling_forecast_config.json" --data-name-list "PJM.csv" --strategy-args '{"horizon": 360, "target_channel": [-1]}' --adapter "transformer_adapter" --model-name "time_series_library.TemporalFusionTransformer" --model-hyper-params '{"batch_size": 128, "c_out": 3, "covariate_dim": 2, "d_ff": 64, "d_layers": 1, "d_model": 128, "data": "PJM", "dec_in": 3, "dropout": 0.1, "e_layers": 1, "enc_in": 3, "factor": 3, "features": "MS", "horizon": 360, "label_len": 48, "lr": 0.001, "n_heads": 8, "norm": true, "num_epochs": 10, "patience": 5, "seq_len": 720}' --gpus 0 --num-workers 1 --timeout 60000 --save-path "PJM/TemporalFusionTransformer"

python ./scripts/run_benchmark.py --config-path "rolling_forecast_config.json" --data-name-list "BE.csv" --strategy-args '{"horizon": 24, "target_channel": [-1]}' --adapter "transformer_adapter" --model-name "time_series_library.TemporalFusionTransformer" --model-hyper-params '{"batch_size": 128, "c_out": 4, "covariate_dim": 2, "d_ff": 32, "d_layers": 2, "d_model": 128, "data": "BE", "dec_in": 4, "dropout": 0.1, "e_layers": 2, "enc_in": 4, "factor": 3, "features": "MS", "horizon": 24, "label_len": 48, "lr": 0.001, "n_heads": 8, "norm": true, "num_epochs": 10, "patience": 5, "seq_len": 168}' --gpus 0 --num-workers 1 --timeout 60000 --save-path "BE/TemporalFusionTransformer"

python ./scripts/run_benchmark.py --config-path "rolling_forecast_config.json" --data-name-list "BE.csv" --strategy-args '{"horizon": 360, "target_channel": [-1]}' --adapter "transformer_adapter" --model-name "time_series_library.TemporalFusionTransformer" --model-hyper-params '{"batch_size": 128, "c_out": 4, "covariate_dim": 2, "d_ff": 32, "d_layers": 2, "d_model": 128, "data": "BE", "dec_in": 4, "dropout": 0.1, "e_layers": 2, "enc_in": 4, "factor": 3, "features": "MS", "horizon": 360, "label_len": 48, "lr": 0.001, "n_heads": 8, "norm": true, "num_epochs": 10, "patience": 5, "seq_len": 720}' --gpus 0 --num-workers 1 --timeout 60000 --save-path "BE/TemporalFusionTransformer"

python ./scripts/run_benchmark.py --config-path "rolling_forecast_config.json" --data-name-list "FR.csv" --strategy-args '{"horizon": 24, "target_channel": [-1]}' --adapter "transformer_adapter" --model-name "time_series_library.TemporalFusionTransformer" --model-hyper-params '{"batch_size": 128, "c_out": 4, "covariate_dim": 2, "d_ff": 32, "d_layers": 2, "d_model": 128, "data": "FR", "dec_in": 4, "dropout": 0.1, "e_layers": 2, "enc_in": 4, "factor": 3, "features": "MS", "horizon": 24, "label_len": 48, "lr": 0.001, "n_heads": 8, "norm": true, "num_epochs": 10, "patience": 5, "seq_len": 168}' --gpus 0 --num-workers 1 --timeout 60000 --save-path "FR/TemporalFusionTransformer"

python ./scripts/run_benchmark.py --config-path "rolling_forecast_config.json" --data-name-list "FR.csv" --strategy-args '{"horizon": 360, "target_channel": [-1]}' --adapter "transformer_adapter" --model-name "time_series_library.TemporalFusionTransformer" --model-hyper-params '{"batch_size": 128, "c_out": 4, "covariate_dim": 2, "d_ff": 32, "d_layers": 2, "d_model": 128, "data": "FR", "dec_in": 4, "dropout": 0.1, "e_layers": 2, "enc_in": 4, "factor": 3, "features": "MS", "horizon": 360, "label_len": 48, "lr": 0.001, "n_heads": 8, "norm": true, "num_epochs": 10, "patience": 5, "seq_len": 720}' --gpus 0 --num-workers 1 --timeout 60000 --save-path "FR/TemporalFusionTransformer"

python ./scripts/run_benchmark.py --config-path "rolling_forecast_config.json" --data-name-list "DE.csv" --strategy-args '{"horizon": 24, "target_channel": [-1]}' --adapter "transformer_adapter" --model-name "time_series_library.TemporalFusionTransformer" --model-hyper-params '{"batch_size": 128, "c_out": 3, "covariate_dim": 2, "d_ff": 64, "d_layers": 1, "d_model": 128, "data": "DE", "dec_in": 3, "dropout": 0.1, "e_layers": 1, "enc_in": 3, "factor": 3, "features": "MS", "horizon": 24, "label_len": 48, "lr": 0.001, "n_heads": 8, "norm": true, "num_epochs": 10, "patience": 5, "seq_len": 168}' --gpus 0 --num-workers 1 --timeout 60000 --save-path "DE/TemporalFusionTransformer"

python ./scripts/run_benchmark.py --config-path "rolling_forecast_config.json" --data-name-list "DE.csv" --strategy-args '{"horizon": 360, "target_channel": [-1]}' --adapter "transformer_adapter" --model-name "time_series_library.TemporalFusionTransformer" --model-hyper-params '{"batch_size": 128, "c_out": 3, "covariate_dim": 2, "d_ff": 64, "d_layers": 1, "d_model": 128, "data": "DE", "dec_in": 3, "dropout": 0.1, "e_layers": 1, "enc_in": 3, "factor": 3, "features": "MS", "horizon": 360, "label_len": 48, "lr": 0.001, "n_heads": 8, "norm": true, "num_epochs": 10, "patience": 5, "seq_len": 720}' --gpus 0 --num-workers 1 --timeout 60000 --save-path "DE/TemporalFusionTransformer"

python ./scripts/run_benchmark.py --config-path "rolling_forecast_config.json" --data-name-list "Energy.csv" --strategy-args '{"horizon": 24, "target_channel": [-1]}' --adapter "transformer_adapter" --model-name "time_series_library.TemporalFusionTransformer" --model-hyper-params '{"batch_size": 128, "c_out": 7, "covariate_dim": 5, "d_ff": 32, "d_layers": 2, "d_model": 128, "data": "Energy", "dec_in": 7, "dropout": 0.1, "e_layers": 2, "enc_in": 7, "factor": 3, "features": "MS", "horizon": 24, "label_len": 48, "lr": 0.01, "n_heads": 8, "norm": true, "num_epochs": 10, "patience": 5, "seq_len": 168}' --gpus 0 --num-workers 1 --timeout 60000 --save-path "Energy/TemporalFusionTransformer"

python ./scripts/run_benchmark.py --config-path "rolling_forecast_config.json" --data-name-list "Energy.csv" --strategy-args '{"horizon": 360, "target_channel": [-1]}' --adapter "transformer_adapter" --model-name "time_series_library.TemporalFusionTransformer" --model-hyper-params '{"batch_size": 128, "c_out": 7, "covariate_dim": 5, "d_ff": 32, "d_layers": 2, "d_model": 128, "data": "Energy", "dec_in": 7, "dropout": 0.1, "e_layers": 2, "enc_in": 7, "factor": 3, "features": "MS", "horizon": 360, "label_len": 48, "lr": 0.01, "n_heads": 8, "norm": true, "num_epochs": 10, "patience": 5, "seq_len": 720}' --gpus 0 --num-workers 1 --timeout 60000 --save-path "Energy/TemporalFusionTransformer"

python ./scripts/run_benchmark.py --config-path "rolling_forecast_config.json" --data-name-list "Sdwpfm1.csv" --strategy-args '{"horizon": 24, "target_channel": [-1]}' --adapter "transformer_adapter" --model-name "time_series_library.TemporalFusionTransformer" --model-hyper-params '{"batch_size": 32, "c_out": 7, "covariate_dim": 6, "d_ff": 512, "d_layers": 1, "d_model": 128, "data": "Sdwpfm1", "dec_in": 7, "dropout": 0.3, "e_layers": 2, "enc_in": 7, "factor": 3, "features": "MS", "horizon": 24, "label_len": 48, "lr": 0.001, "mlp_hidden_dims": 128, "n_heads": 8, "norm": true, "num_epochs": 10, "patience": 3, "seq_len": 168}' --gpus 0 --num-workers 1 --timeout 60000 --save-path "Sdwpfm1/TemporalFusionTransformer"

python ./scripts/run_benchmark.py --config-path "rolling_forecast_config.json" --data-name-list "Sdwpfm1.csv" --strategy-args '{"horizon": 360, "target_channel": [-1]}' --adapter "transformer_adapter" --model-name "time_series_library.TemporalFusionTransformer" --model-hyper-params '{"batch_size": 32, "c_out": 7, "covariate_dim": 6, "d_ff": 512, "d_layers": 1, "d_model": 128, "data": "Sdwpfm1", "dec_in": 7, "dropout": 0.3, "e_layers": 2, "enc_in": 7, "factor": 3, "features": "MS", "horizon": 360, "label_len": 48, "lr": 0.001, "mlp_hidden_dims": 128, "n_heads": 8, "norm": true, "num_epochs": 10, "patience": 3, "seq_len": 720}' --gpus 0 --num-workers 1 --timeout 60000 --save-path "Sdwpfm1/TemporalFusionTransformer"

python ./scripts/run_benchmark.py --config-path "rolling_forecast_config.json" --data-name-list "Sdwpfm2.csv" --strategy-args '{"horizon": 24, "target_channel": [-1]}' --adapter "transformer_adapter" --model-name "time_series_library.TemporalFusionTransformer" --model-hyper-params '{"batch_size": 32, "c_out": 7, "covariate_dim": 6, "d_ff": 512, "d_layers": 1, "d_model": 128, "data": "Sdwpfm2", "dec_in": 7, "dropout": 0.3, "e_layers": 2, "enc_in": 7, "factor": 3, "features": "MS", "horizon": 24, "label_len": 48, "lr": 0.001, "mlp_hidden_dims": 128, "n_heads": 8, "norm": true, "num_epochs": 10, "patience": 3, "seq_len": 168}' --gpus 0 --num-workers 1 --timeout 60000 --save-path "Sdwpfm2/TemporalFusionTransformer"

python ./scripts/run_benchmark.py --config-path "rolling_forecast_config.json" --data-name-list "Sdwpfm2.csv" --strategy-args '{"horizon": 360, "target_channel": [-1]}' --adapter "transformer_adapter" --model-name "time_series_library.TemporalFusionTransformer" --model-hyper-params '{"batch_size": 32, "c_out": 7, "covariate_dim": 6, "d_ff": 512, "d_layers": 1, "d_model": 128, "data": "Sdwpfm2", "dec_in": 7, "dropout": 0.3, "e_layers": 2, "enc_in": 7, "factor": 3, "features": "MS", "horizon": 360, "label_len": 48, "lr": 0.001, "mlp_hidden_dims": 128, "n_heads": 8, "norm": true, "num_epochs": 10, "patience": 3, "seq_len": 720}' --gpus 0 --num-workers 1 --timeout 60000 --save-path "Sdwpfm2/TemporalFusionTransformer"

python ./scripts/run_benchmark.py --config-path "rolling_forecast_config.json" --data-name-list "Sdwpfh1.csv" --strategy-args '{"horizon": 24, "target_channel": [-1]}' --adapter "transformer_adapter" --model-name "time_series_library.TemporalFusionTransformer" --model-hyper-params '{"batch_size": 32, "c_out": 7, "covariate_dim": 6, "d_ff": 512, "d_layers": 1, "d_model": 128, "data": "Sdwpfh1", "dec_in": 7, "dropout": 0.1, "e_layers": 2, "enc_in": 7, "factor": 3, "features": "MS", "horizon": 24, "label_len": 48, "lr": 0.001, "mlp_hidden_dims": 128, "n_heads": 8, "norm": true, "num_epochs": 10, "patience": 3, "seq_len": 168}' --gpus 0 --num-workers 1 --timeout 60000 --save-path "Sdwpfh1/TemporalFusionTransformer"

python ./scripts/run_benchmark.py --config-path "rolling_forecast_config.json" --data-name-list "Sdwpfh1.csv" --strategy-args '{"horizon": 360, "target_channel": [-1]}' --adapter "transformer_adapter" --model-name "time_series_library.TemporalFusionTransformer" --model-hyper-params '{"batch_size": 32, "c_out": 7, "covariate_dim": 6, "d_ff": 512, "d_layers": 1, "d_model": 128, "data": "Sdwpfh1", "dec_in": 7, "dropout": 0.1, "e_layers": 2, "enc_in": 7, "factor": 3, "features": "MS", "horizon": 360, "label_len": 48, "lr": 0.001, "mlp_hidden_dims": 128, "n_heads": 8, "norm": true, "num_epochs": 10, "patience": 3, "seq_len": 720}' --gpus 0 --num-workers 1 --timeout 60000 --save-path "Sdwpfh1/TemporalFusionTransformer"

python ./scripts/run_benchmark.py --config-path "rolling_forecast_config.json" --data-name-list "Sdwpfh2.csv" --strategy-args '{"horizon": 24, "target_channel": [-1]}' --adapter "transformer_adapter" --model-name "time_series_library.TemporalFusionTransformer" --model-hyper-params '{"batch_size": 32, "c_out": 7, "covariate_dim": 6, "d_ff": 1024, "d_layers": 1, "d_model": 128, "data": "Sdwpfh2", "dec_in": 7, "dropout": 0.0, "e_layers": 2, "enc_in": 7, "factor": 3, "features": "MS", "horizon": 24, "label_len": 48, "lr": 0.001, "n_heads": 8, "norm": true, "num_epochs": 10, "patience": 3, "seq_len": 168}' --gpus 0 --num-workers 1 --timeout 60000 --save-path "Sdwpfh2/TemporalFusionTransformer"

python ./scripts/run_benchmark.py --config-path "rolling_forecast_config.json" --data-name-list "Sdwpfh2.csv" --strategy-args '{"horizon": 360, "target_channel": [-1]}' --adapter "transformer_adapter" --model-name "time_series_library.TemporalFusionTransformer" --model-hyper-params '{"batch_size": 32, "c_out": 7, "covariate_dim": 6, "d_ff": 1024, "d_layers": 1, "d_model": 128, "data": "Sdwpfh2", "dec_in": 7, "dropout": 0.0, "e_layers": 2, "enc_in": 7, "factor": 3, "features": "MS", "horizon": 360, "label_len": 48, "lr": 0.001, "n_heads": 8, "norm": true, "num_epochs": 10, "patience": 3, "seq_len": 720}' --gpus 0 --num-workers 1 --timeout 60000 --save-path "Sdwpfh2/TemporalFusionTransformer"

python ./scripts/run_benchmark.py --config-path "rolling_forecast_config.json" --data-name-list "Colbun.csv" --strategy-args '{"horizon": 10, "target_channel": [-1]}' --adapter "transformer_adapter" --model-name "time_series_library.TemporalFusionTransformer" --model-hyper-params '{"batch_size": 128, "c_out": 3, "covariate_dim": 2, "d_ff": 64, "d_layers": 1, "d_model": 64, "data": "Colbun", "dec_in": 3, "dropout": 0.1, "e_layers": 1, "enc_in": 3, "factor": 3, "features": "MS", "horizon": 10, "label_len": 48, "lr": 0.01, "n_heads": 8, "norm": true, "num_epochs": 10, "patience": 5, "seq_len": 60}' --gpus 0 --num-workers 1 --timeout 60000 --save-path "Colbun/TemporalFusionTransformer"

python ./scripts/run_benchmark.py --config-path "rolling_forecast_config.json" --data-name-list "Colbun.csv" --strategy-args '{"horizon": 30, "target_channel": [-1]}' --adapter "transformer_adapter" --model-name "time_series_library.TemporalFusionTransformer" --model-hyper-params '{"batch_size": 128, "c_out": 3, "covariate_dim": 2, "d_ff": 64, "d_layers": 1, "d_model": 64, "data": "Colbun", "dec_in": 3, "dropout": 0.1, "e_layers": 1, "enc_in": 3, "factor": 3, "features": "MS", "horizon": 30, "label_len": 48, "lr": 0.01, "n_heads": 8, "norm": true, "num_epochs": 10, "patience": 5, "seq_len": 180}' --gpus 0 --num-workers 1 --timeout 60000 --save-path "Colbun/TemporalFusionTransformer"

python ./scripts/run_benchmark.py --config-path "rolling_forecast_config.json" --data-name-list "Rapel.csv" --strategy-args '{"horizon": 10, "target_channel": [-1]}' --adapter "transformer_adapter" --model-name "time_series_library.TemporalFusionTransformer" --model-hyper-params '{"batch_size": 128, "c_out": 3, "covariate_dim": 2, "d_ff": 32, "d_layers": 1, "d_model": 64, "data": "Rapel", "dec_in": 3, "dropout": 0.1, "e_layers": 2, "enc_in": 3, "factor": 3, "features": "MS", "horizon": 10, "label_len": 48, "lr": 0.001, "n_heads": 8, "norm": true, "num_epochs": 10, "patience": 5, "seq_len": 60}' --gpus 0 --num-workers 1 --timeout 60000 --save-path "Rapel/TemporalFusionTransformer"

python ./scripts/run_benchmark.py --config-path "rolling_forecast_config.json" --data-name-list "Rapel.csv" --strategy-args '{"horizon": 30, "target_channel": [-1]}' --adapter "transformer_adapter" --model-name "time_series_library.TemporalFusionTransformer" --model-hyper-params '{"batch_size": 128, "c_out": 3, "covariate_dim": 2, "d_ff": 32, "d_layers": 1, "d_model": 64, "data": "Rapel", "dec_in": 3, "dropout": 0.1, "e_layers": 2, "enc_in": 3, "factor": 3, "features": "MS", "horizon": 30, "label_len": 48, "lr": 0.001, "n_heads": 8, "norm": true, "num_epochs": 10, "patience": 5, "seq_len": 180}' --gpus 0 --num-workers 1 --timeout 60000 --save-path "Rapel/TemporalFusionTransformer"

python ./scripts/run_benchmark.py --config-path "rolling_forecast_config.json" --data-name-list "ETTh1.csv" --strategy-args '{"horizon": 96, "target_channel": [-1]}' --adapter "transformer_adapter" --model-name "time_series_library.TemporalFusionTransformer" --model-hyper-params '{"batch_size": 32, "c_out": 7, "covariate_dim": 6, "d_ff": 512, "d_layers": 1, "d_model": 128, "data": "ETTh1", "dec_in": 7, "dropout": 0.3, "e_layers": 2, "enc_in": 7, "factor": 3, "features": "MS", "horizon": 96, "label_len": 48, "lr": 0.001, "n_heads": 8, "norm": true, "num_epochs": 10, "patience": 3, "seq_len": 96}' --gpus 0 --num-workers 1 --timeout 60000 --save-path "ETTh1/TemporalFusionTransformer"

python ./scripts/run_benchmark.py --config-path "rolling_forecast_config.json" --data-name-list "ETTh1.csv" --strategy-args '{"horizon": 192, "target_channel": [-1]}' --adapter "transformer_adapter" --model-name "time_series_library.TemporalFusionTransformer" --model-hyper-params '{"batch_size": 32, "c_out": 7, "covariate_dim": 6, "d_ff": 512, "d_layers": 1, "d_model": 128, "data": "ETTh1", "dec_in": 7, "dropout": 0.3, "e_layers": 2, "enc_in": 7, "factor": 3, "features": "MS", "horizon": 192, "label_len": 48, "lr": 0.001, "n_heads": 8, "norm": true, "num_epochs": 10, "patience": 3, "seq_len": 96}' --gpus 0 --num-workers 1 --timeout 60000 --save-path "ETTh1/TemporalFusionTransformer"

python ./scripts/run_benchmark.py --config-path "rolling_forecast_config.json" --data-name-list "ETTh1.csv" --strategy-args '{"horizon": 336, "target_channel": [-1]}' --adapter "transformer_adapter" --model-name "time_series_library.TemporalFusionTransformer" --model-hyper-params '{"batch_size": 32, "c_out": 7, "covariate_dim": 6, "d_ff": 512, "d_layers": 1, "d_model": 128, "data": "ETTh1", "dec_in": 7, "dropout": 0.3, "e_layers": 2, "enc_in": 7, "factor": 3, "features": "MS", "horizon": 336, "label_len": 48, "lr": 0.001, "n_heads": 8, "norm": true, "num_epochs": 10, "patience": 3, "seq_len": 96}' --gpus 0 --num-workers 1 --timeout 60000 --save-path "ETTh1/TemporalFusionTransformer"

python ./scripts/run_benchmark.py --config-path "rolling_forecast_config.json" --data-name-list "ETTh1.csv" --strategy-args '{"horizon": 720, "target_channel": [-1]}' --adapter "transformer_adapter" --model-name "time_series_library.TemporalFusionTransformer" --model-hyper-params '{"batch_size": 32, "c_out": 7, "covariate_dim": 6, "d_ff": 512, "d_layers": 1, "d_model": 128, "data": "ETTh1", "dec_in": 7, "dropout": 0.3, "e_layers": 2, "enc_in": 7, "factor": 3, "features": "MS", "horizon": 720, "label_len": 48, "lr": 0.001, "n_heads": 8, "norm": true, "num_epochs": 10, "patience": 3, "seq_len": 96}' --gpus 0 --num-workers 1 --timeout 60000 --save-path "ETTh1/TemporalFusionTransformer"

python ./scripts/run_benchmark.py --config-path "rolling_forecast_config.json" --data-name-list "ETTh2.csv" --strategy-args '{"horizon": 96, "target_channel": [-1]}' --adapter "transformer_adapter" --model-name "time_series_library.TemporalFusionTransformer" --model-hyper-params '{"batch_size": 16, "c_out": 7, "covariate_dim": 6, "d_ff": 32, "d_layers": 1, "d_model": 32, "data": "ETTh2", "dec_in": 7, "dropout": 0.3, "e_layers": 1, "enc_in": 7, "factor": 3, "features": "MS", "horizon": 96, "label_len": 48, "lr": 1e-05, "n_heads": 8, "norm": true, "num_epochs": 10, "patience": 3, "seq_len": 96}' --gpus 0 --num-workers 1 --timeout 60000 --save-path "ETTh2/TemporalFusionTransformer"

python ./scripts/run_benchmark.py --config-path "rolling_forecast_config.json" --data-name-list "ETTh2.csv" --strategy-args '{"horizon": 192, "target_channel": [-1]}' --adapter "transformer_adapter" --model-name "time_series_library.TemporalFusionTransformer" --model-hyper-params '{"batch_size": 16, "c_out": 7, "covariate_dim": 6, "d_ff": 32, "d_layers": 1, "d_model": 32, "data": "ETTh2", "dec_in": 7, "dropout": 0.3, "e_layers": 1, "enc_in": 7, "factor": 3, "features": "MS", "horizon": 192, "label_len": 48, "lr": 1e-05, "n_heads": 8, "norm": true, "num_epochs": 10, "patience": 3, "seq_len": 96}' --gpus 0 --num-workers 1 --timeout 60000 --save-path "ETTh2/TemporalFusionTransformer"

python ./scripts/run_benchmark.py --config-path "rolling_forecast_config.json" --data-name-list "ETTh2.csv" --strategy-args '{"horizon": 336, "target_channel": [-1]}' --adapter "transformer_adapter" --model-name "time_series_library.TemporalFusionTransformer" --model-hyper-params '{"batch_size": 16, "c_out": 7, "covariate_dim": 6, "d_ff": 32, "d_layers": 1, "d_model": 32, "data": "ETTh2", "dec_in": 7, "dropout": 0.3, "e_layers": 1, "enc_in": 7, "factor": 3, "features": "MS", "horizon": 336, "label_len": 48, "lr": 1e-05, "n_heads": 8, "norm": true, "num_epochs": 10, "patience": 3, "seq_len": 96}' --gpus 0 --num-workers 1 --timeout 60000 --save-path "ETTh2/TemporalFusionTransformer"

python ./scripts/run_benchmark.py --config-path "rolling_forecast_config.json" --data-name-list "ETTh2.csv" --strategy-args '{"horizon": 720, "target_channel": [-1]}' --adapter "transformer_adapter" --model-name "time_series_library.TemporalFusionTransformer" --model-hyper-params '{"batch_size": 16, "c_out": 7, "covariate_dim": 6, "d_ff": 32, "d_layers": 1, "d_model": 32, "data": "ETTh2", "dec_in": 7, "dropout": 0.3, "e_layers": 1, "enc_in": 7, "factor": 3, "features": "MS", "horizon": 720, "label_len": 48, "lr": 1e-05, "n_heads": 8, "norm": true, "num_epochs": 10, "patience": 3, "seq_len": 96}' --gpus 0 --num-workers 1 --timeout 60000 --save-path "ETTh2/TemporalFusionTransformer"

python ./scripts/run_benchmark.py --config-path "rolling_forecast_config.json" --data-name-list "ETTm1.csv" --strategy-args '{"horizon": 96, "target_channel": [-1]}' --adapter "transformer_adapter" --model-name "time_series_library.TemporalFusionTransformer" --model-hyper-params '{"batch_size": 32, "c_out": 7, "covariate_dim": 6, "d_ff": 512, "d_layers": 1, "d_model": 128, "data": "ETTm1", "dec_in": 7, "dropout": 0.3, "e_layers": 2, "enc_in": 7, "factor": 3, "features": "MS", "horizon": 96, "label_len": 48, "lr": 0.0001, "n_heads": 8, "norm": true, "num_epochs": 10, "patience": 3, "seq_len": 96}' --gpus 0 --num-workers 1 --timeout 60000 --save-path "ETTm1/TemporalFusionTransformer"

python ./scripts/run_benchmark.py --config-path "rolling_forecast_config.json" --data-name-list "ETTm1.csv" --strategy-args '{"horizon": 192, "target_channel": [-1]}' --adapter "transformer_adapter" --model-name "time_series_library.TemporalFusionTransformer" --model-hyper-params '{"batch_size": 32, "c_out": 7, "covariate_dim": 6, "d_ff": 512, "d_layers": 1, "d_model": 128, "data": "ETTm1", "dec_in": 7, "dropout": 0.3, "e_layers": 2, "enc_in": 7, "factor": 3, "features": "MS", "horizon": 192, "label_len": 48, "lr": 0.0001, "n_heads": 8, "norm": true, "num_epochs": 10, "patience": 3, "seq_len": 96}' --gpus 0 --num-workers 1 --timeout 60000 --save-path "ETTm1/TemporalFusionTransformer"

python ./scripts/run_benchmark.py --config-path "rolling_forecast_config.json" --data-name-list "ETTm1.csv" --strategy-args '{"horizon": 336, "target_channel": [-1]}' --adapter "transformer_adapter" --model-name "time_series_library.TemporalFusionTransformer" --model-hyper-params '{"batch_size": 32, "c_out": 7, "covariate_dim": 6, "d_ff": 512, "d_layers": 1, "d_model": 128, "data": "ETTm1", "dec_in": 7, "dropout": 0.3, "e_layers": 2, "enc_in": 7, "factor": 3, "features": "MS", "horizon": 336, "label_len": 48, "lr": 0.0001, "n_heads": 8, "norm": true, "num_epochs": 10, "patience": 3, "seq_len": 96}' --gpus 0 --num-workers 1 --timeout 60000 --save-path "ETTm1/TemporalFusionTransformer"

python ./scripts/run_benchmark.py --config-path "rolling_forecast_config.json" --data-name-list "ETTm1.csv" --strategy-args '{"horizon": 720, "target_channel": [-1]}' --adapter "transformer_adapter" --model-name "time_series_library.TemporalFusionTransformer" --model-hyper-params '{"batch_size": 32, "c_out": 7, "covariate_dim": 6, "d_ff": 512, "d_layers": 1, "d_model": 128, "data": "ETTm1", "dec_in": 7, "dropout": 0.3, "e_layers": 2, "enc_in": 7, "factor": 3, "features": "MS", "horizon": 720, "label_len": 48, "lr": 0.0001, "n_heads": 8, "norm": true, "num_epochs": 10, "patience": 3, "seq_len": 96}' --gpus 0 --num-workers 1 --timeout 60000 --save-path "ETTm1/TemporalFusionTransformer"

python ./scripts/run_benchmark.py --config-path "rolling_forecast_config.json" --data-name-list "ETTm2.csv" --strategy-args '{"horizon": 96, "target_channel": [-1]}' --adapter "transformer_adapter" --model-name "time_series_library.TemporalFusionTransformer" --model-hyper-params '{"batch_size": 32, "c_out": 7, "covariate_dim": 6, "d_ff": 32, "d_layers": 1, "d_model": 64, "data": "ETTm2", "dec_in": 7, "dropout": 0.0, "e_layers": 2, "enc_in": 7, "factor": 3, "features": "MS", "horizon": 96, "label_len": 48, "lr": 0.01, "n_heads": 8, "norm": true, "num_epochs": 10, "patience": 3, "seq_len": 96}' --gpus 0 --num-workers 1 --timeout 60000 --save-path "ETTm2/TemporalFusionTransformer"

python ./scripts/run_benchmark.py --config-path "rolling_forecast_config.json" --data-name-list "ETTm2.csv" --strategy-args '{"horizon": 192, "target_channel": [-1]}' --adapter "transformer_adapter" --model-name "time_series_library.TemporalFusionTransformer" --model-hyper-params '{"batch_size": 32, "c_out": 7, "covariate_dim": 6, "d_ff": 32, "d_layers": 1, "d_model": 64, "data": "ETTm2", "dec_in": 7, "dropout": 0.0, "e_layers": 2, "enc_in": 7, "factor": 3, "features": "MS", "horizon": 192, "label_len": 48, "lr": 0.01, "n_heads": 8, "norm": true, "num_epochs": 10, "patience": 3, "seq_len": 96}' --gpus 0 --num-workers 1 --timeout 60000 --save-path "ETTm2/TemporalFusionTransformer"

python ./scripts/run_benchmark.py --config-path "rolling_forecast_config.json" --data-name-list "ETTm2.csv" --strategy-args '{"horizon": 336, "target_channel": [-1]}' --adapter "transformer_adapter" --model-name "time_series_library.TemporalFusionTransformer" --model-hyper-params '{"batch_size": 32, "c_out": 7, "covariate_dim": 6, "d_ff": 32, "d_layers": 1, "d_model": 64, "data": "ETTm2", "dec_in": 7, "dropout": 0.0, "e_layers": 2, "enc_in": 7, "factor": 3, "features": "MS", "horizon": 336, "label_len": 48, "lr": 0.01, "n_heads": 8, "norm": true, "num_epochs": 10, "patience": 3, "seq_len": 96}' --gpus 0 --num-workers 1 --timeout 60000 --save-path "ETTm2/TemporalFusionTransformer"

python ./scripts/run_benchmark.py --config-path "rolling_forecast_config.json" --data-name-list "ETTm2.csv" --strategy-args '{"horizon": 720, "target_channel": [-1]}' --adapter "transformer_adapter" --model-name "time_series_library.TemporalFusionTransformer" --model-hyper-params '{"batch_size": 32, "c_out": 7, "covariate_dim": 6, "d_ff": 32, "d_layers": 1, "d_model": 64, "data": "ETTm2", "dec_in": 7, "dropout": 0.0, "e_layers": 2, "enc_in": 7, "factor": 3, "features": "MS", "horizon": 720, "label_len": 48, "lr": 0.01, "n_heads": 8, "norm": true, "num_epochs": 10, "patience": 3, "seq_len": 96}' --gpus 0 --num-workers 1 --timeout 60000 --save-path "ETTm2/TemporalFusionTransformer"

python ./scripts/run_benchmark.py --config-path "rolling_forecast_config.json" --data-name-list "Weather.csv" --strategy-args '{"horizon": 96, "target_channel": [-1]}' --adapter "transformer_adapter" --model-name "time_series_library.TemporalFusionTransformer" --model-hyper-params '{"batch_size": 32, "c_out": 21, "covariate_dim": 20, "d_ff": 512, "d_layers": 1, "d_model": 128, "data": "Weather", "dec_in": 21, "dropout": 0.3, "e_layers": 2, "enc_in": 21, "factor": 3, "features": "MS", "horizon": 96, "label_len": 48, "lr": 0.0005, "n_heads": 8, "norm": true, "num_epochs": 10, "patience": 3, "seq_len": 96}' --gpus 0 --num-workers 1 --timeout 60000 --save-path "Weather/TemporalFusionTransformer"

python ./scripts/run_benchmark.py --config-path "rolling_forecast_config.json" --data-name-list "Weather.csv" --strategy-args '{"horizon": 192, "target_channel": [-1]}' --adapter "transformer_adapter" --model-name "time_series_library.TemporalFusionTransformer" --model-hyper-params '{"batch_size": 32, "c_out": 21, "covariate_dim": 20, "d_ff": 512, "d_layers": 1, "d_model": 128, "data": "Weather", "dec_in": 21, "dropout": 0.3, "e_layers": 2, "enc_in": 21, "factor": 3, "features": "MS", "horizon": 192, "label_len": 48, "lr": 0.0005, "n_heads": 8, "norm": true, "num_epochs": 10, "patience": 3, "seq_len": 96}' --gpus 0 --num-workers 1 --timeout 60000 --save-path "Weather/TemporalFusionTransformer"

python ./scripts/run_benchmark.py --config-path "rolling_forecast_config.json" --data-name-list "Weather.csv" --strategy-args '{"horizon": 336, "target_channel": [-1]}' --adapter "transformer_adapter" --model-name "time_series_library.TemporalFusionTransformer" --model-hyper-params '{"batch_size": 32, "c_out": 21, "covariate_dim": 20, "d_ff": 512, "d_layers": 1, "d_model": 128, "data": "Weather", "dec_in": 21, "dropout": 0.3, "e_layers": 2, "enc_in": 21, "factor": 3, "features": "MS", "horizon": 336, "label_len": 48, "lr": 0.0005, "n_heads": 8, "norm": true, "num_epochs": 10, "patience": 3, "seq_len": 96}' --gpus 0 --num-workers 1 --timeout 60000 --save-path "Weather/TemporalFusionTransformer"

python ./scripts/run_benchmark.py --config-path "rolling_forecast_config.json" --data-name-list "Weather.csv" --strategy-args '{"horizon": 720, "target_channel": [-1]}' --adapter "transformer_adapter" --model-name "time_series_library.TemporalFusionTransformer" --model-hyper-params '{"batch_size": 32, "c_out": 21, "covariate_dim": 20, "d_ff": 512, "d_layers": 1, "d_model": 128, "data": "Weather", "dec_in": 21, "dropout": 0.3, "e_layers": 2, "enc_in": 21, "factor": 3, "features": "MS", "horizon": 720, "label_len": 48, "lr": 0.0005, "n_heads": 8, "norm": true, "num_epochs": 10, "patience": 3, "seq_len": 96}' --gpus 0 --num-workers 1 --timeout 60000 --save-path "Weather/TemporalFusionTransformer"

python ./scripts/run_benchmark.py --config-path "rolling_forecast_config.json" --data-name-list "Electricity.csv" --strategy-args '{"horizon": 96, "target_channel": [-1]}' --adapter "transformer_adapter" --model-name "time_series_library.TemporalFusionTransformer" --model-hyper-params '{"batch_size": 32, "c_out": 321, "covariate_dim": 320, "d_ff": 128, "d_layers": 1, "d_model": 32, "data": "Electricity", "dec_in": 321, "dropout": 0.3, "e_layers": 2, "enc_in": 321, "factor": 3, "features": "MS", "horizon": 96, "label_len": 48, "lr": 0.0001, "n_heads": 8, "norm": true, "num_epochs": 10, "patience": 3, "seq_len": 96}' --gpus 0 --num-workers 1 --timeout 60000 --save-path "Electricity/TemporalFusionTransformer"

python ./scripts/run_benchmark.py --config-path "rolling_forecast_config.json" --data-name-list "Electricity.csv" --strategy-args '{"horizon": 192, "target_channel": [-1]}' --adapter "transformer_adapter" --model-name "time_series_library.TemporalFusionTransformer" --model-hyper-params '{"batch_size": 32, "c_out": 321, "covariate_dim": 320, "d_ff": 128, "d_layers": 1, "d_model": 32, "data": "Electricity", "dec_in": 321, "dropout": 0.3, "e_layers": 2, "enc_in": 321, "factor": 3, "features": "MS", "horizon": 192, "label_len": 48, "lr": 0.0001, "n_heads": 8, "norm": true, "num_epochs": 10, "patience": 3, "seq_len": 96}' --gpus 0 --num-workers 1 --timeout 60000 --save-path "Electricity/TemporalFusionTransformer"

python ./scripts/run_benchmark.py --config-path "rolling_forecast_config.json" --data-name-list "Electricity.csv" --strategy-args '{"horizon": 336, "target_channel": [-1]}' --adapter "transformer_adapter" --model-name "time_series_library.TemporalFusionTransformer" --model-hyper-params '{"batch_size": 32, "c_out": 321, "covariate_dim": 320, "d_ff": 128, "d_layers": 1, "d_model": 32, "data": "Electricity", "dec_in": 321, "dropout": 0.3, "e_layers": 2, "enc_in": 321, "factor": 3, "features": "MS", "horizon": 336, "label_len": 48, "lr": 0.0001, "n_heads": 8, "norm": true, "num_epochs": 10, "patience": 3, "seq_len": 96}' --gpus 0 --num-workers 1 --timeout 60000 --save-path "Electricity/TemporalFusionTransformer"

python ./scripts/run_benchmark.py --config-path "rolling_forecast_config.json" --data-name-list "Electricity.csv" --strategy-args '{"horizon": 720, "target_channel": [-1]}' --adapter "transformer_adapter" --model-name "time_series_library.TemporalFusionTransformer" --model-hyper-params '{"batch_size": 32, "c_out": 321, "covariate_dim": 320, "d_ff": 128, "d_layers": 1, "d_model": 32, "data": "Electricity", "dec_in": 321, "dropout": 0.3, "e_layers": 2, "enc_in": 321, "factor": 3, "features": "MS", "horizon": 720, "label_len": 48, "lr": 0.0001, "n_heads": 8, "norm": true, "num_epochs": 10, "patience": 3, "seq_len": 96}' --gpus 0 --num-workers 1 --timeout 60000 --save-path "Electricity/TemporalFusionTransformer"

python ./scripts/run_benchmark.py --config-path "rolling_forecast_config.json" --data-name-list "Traffic.csv" --strategy-args '{"horizon": 96, "target_channel": [-1]}' --adapter "transformer_adapter" --model-name "time_series_library.TemporalFusionTransformer" --model-hyper-params '{"batch_size": 32, "c_out": 862, "covariate_dim": 861, "d_ff": 128, "d_layers": 1, "d_model": 32, "data": "Traffic", "dec_in": 862, "dropout": 0.3, "e_layers": 2, "enc_in": 862, "factor": 3, "features": "MS", "horizon": 96, "label_len": 48, "lr": 0.0001, "n_heads": 4, "norm": true, "num_epochs": 10, "patience": 3, "seq_len": 96}' --gpus 0 --num-workers 1 --timeout 60000 --save-path "Traffic/TemporalFusionTransformer"

python ./scripts/run_benchmark.py --config-path "rolling_forecast_config.json" --data-name-list "Traffic.csv" --strategy-args '{"horizon": 192, "target_channel": [-1]}' --adapter "transformer_adapter" --model-name "time_series_library.TemporalFusionTransformer" --model-hyper-params '{"batch_size": 32, "c_out": 862, "covariate_dim": 861, "d_ff": 128, "d_layers": 1, "d_model": 32, "data": "Traffic", "dec_in": 862, "dropout": 0.3, "e_layers": 2, "enc_in": 862, "factor": 3, "features": "MS", "horizon": 192, "label_len": 48, "lr": 0.0001, "n_heads": 4, "norm": true, "num_epochs": 10, "patience": 3, "seq_len": 96}' --gpus 0 --num-workers 1 --timeout 60000 --save-path "Traffic/TemporalFusionTransformer"

python ./scripts/run_benchmark.py --config-path "rolling_forecast_config.json" --data-name-list "Traffic.csv" --strategy-args '{"horizon": 336, "target_channel": [-1]}' --adapter "transformer_adapter" --model-name "time_series_library.TemporalFusionTransformer" --model-hyper-params '{"batch_size": 32, "c_out": 862, "covariate_dim": 861, "d_ff": 128, "d_layers": 1, "d_model": 32, "data": "Traffic", "dec_in": 862, "dropout": 0.3, "e_layers": 2, "enc_in": 862, "factor": 3, "features": "MS", "horizon": 336, "label_len": 48, "lr": 0.0001, "n_heads": 4, "norm": true, "num_epochs": 10, "patience": 3, "seq_len": 96}' --gpus 0 --num-workers 1 --timeout 60000 --save-path "Traffic/TemporalFusionTransformer"

python ./scripts/run_benchmark.py --config-path "rolling_forecast_config.json" --data-name-list "Traffic.csv" --strategy-args '{"horizon": 720, "target_channel": [-1]}' --adapter "transformer_adapter" --model-name "time_series_library.TemporalFusionTransformer" --model-hyper-params '{"batch_size": 32, "c_out": 862, "covariate_dim": 861, "d_ff": 128, "d_layers": 1, "d_model": 32, "data": "Traffic", "dec_in": 862, "dropout": 0.3, "e_layers": 2, "enc_in": 862, "factor": 3, "features": "MS", "horizon": 720, "label_len": 48, "lr": 0.0001, "n_heads": 4, "norm": true, "num_epochs": 10, "patience": 3, "seq_len": 96}' --gpus 0 --num-workers 1 --timeout 60000 --save-path "Traffic/TemporalFusionTransformer"

python ./scripts/run_benchmark.py --config-path "rolling_forecast_config.json" --data-name-list "Exchange.csv" --strategy-args '{"horizon": 96, "target_channel": [-1]}' --adapter "transformer_adapter" --model-name "time_series_library.TemporalFusionTransformer" --model-hyper-params '{"batch_size": 32, "c_out": 8, "covariate_dim": 7, "d_ff": 64, "d_layers": 1, "d_model": 64, "data": "Exchange", "dec_in": 8, "dropout": 0.1, "e_layers": 2, "enc_in": 8, "factor": 3, "features": "MS", "horizon": 96, "label_len": 48, "lr": 0.01, "n_heads": 8, "norm": true, "num_epochs": 10, "patience": 3, "seq_len": 96}' --gpus 0 --num-workers 1 --timeout 60000 --save-path "Exchange/TemporalFusionTransformer"

python ./scripts/run_benchmark.py --config-path "rolling_forecast_config.json" --data-name-list "Exchange.csv" --strategy-args '{"horizon": 192, "target_channel": [-1]}' --adapter "transformer_adapter" --model-name "time_series_library.TemporalFusionTransformer" --model-hyper-params '{"batch_size": 32, "c_out": 8, "covariate_dim": 7, "d_ff": 64, "d_layers": 1, "d_model": 64, "data": "Exchange", "dec_in": 8, "dropout": 0.1, "e_layers": 2, "enc_in": 8, "factor": 3, "features": "MS", "horizon": 192, "label_len": 48, "lr": 0.01, "n_heads": 8, "norm": true, "num_epochs": 10, "patience": 3, "seq_len": 96}' --gpus 0 --num-workers 1 --timeout 60000 --save-path "Exchange/TemporalFusionTransformer"

python ./scripts/run_benchmark.py --config-path "rolling_forecast_config.json" --data-name-list "Exchange.csv" --strategy-args '{"horizon": 336, "target_channel": [-1]}' --adapter "transformer_adapter" --model-name "time_series_library.TemporalFusionTransformer" --model-hyper-params '{"batch_size": 32, "c_out": 8, "covariate_dim": 7, "d_ff": 64, "d_layers": 1, "d_model": 64, "data": "Exchange", "dec_in": 8, "dropout": 0.1, "e_layers": 2, "enc_in": 8, "factor": 3, "features": "MS", "horizon": 336, "label_len": 48, "lr": 0.01, "n_heads": 8, "norm": true, "num_epochs": 10, "patience": 3, "seq_len": 96}' --gpus 0 --num-workers 1 --timeout 60000 --save-path "Exchange/TemporalFusionTransformer"

python ./scripts/run_benchmark.py --config-path "rolling_forecast_config.json" --data-name-list "Exchange.csv" --strategy-args '{"horizon": 720, "target_channel": [-1]}' --adapter "transformer_adapter" --model-name "time_series_library.TemporalFusionTransformer" --model-hyper-params '{"batch_size": 32, "c_out": 8, "covariate_dim": 7, "d_ff": 64, "d_layers": 1, "d_model": 64, "data": "Exchange", "dec_in": 8, "dropout": 0.1, "e_layers": 2, "enc_in": 8, "factor": 3, "features": "MS", "horizon": 720, "label_len": 48, "lr": 0.01, "n_heads": 8, "norm": true, "num_epochs": 10, "patience": 3, "seq_len": 96}' --gpus 0 --num-workers 1 --timeout 60000 --save-path "Exchange/TemporalFusionTransformer"
